{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"I'm currently a researcher at the National Audiovisual Institute (INA) in Paris metropolitan area (France). At INA, I study machine learning algorithms applied to various digital humanities' tasks, such as natural language processing (e.g., fake news analysis and detection, named entities disambiguation) and speech processing (e.g., speaker diarization, political speech style segmentation). The techniques I employ range from standard machine learning algorithms (e.g., GMM, SVM, K-Means, or Bayesian networks), to deep neural networks (e.g., LSTM, CNN). The main tools I use are TensorFlow , Keras , Scikit-learn , NumPy-SciPy , Pandas , and JupyterLab . Prior to my current position, I worked in signal processing as an electronic and computer science engineer. I then gradually switched to machine learning since 2012, when I started my Ph.D. in speech synthesis at the LIMSI-CNRS from the University of Paris-Sud (now Paris-Saclay ). Written in French and defended in September 2015, it concerned expressive speech synthesis. My research interest range from speech and natural language processing (NLP) to auditory spatial perception : Speech analysis and synthesis, phonetics, prosody Natural language processing, machine learning, deep learning Digital signal processing, audio, acoustics, spatial hearing","title":"Home"},{"location":"3d-audio/","text":"University of Paris-Sud \u2014 Year 2 CS-Master (TC-2) Theoretical and practical material for the Fundamentals of Virtual and Augmented Reality class (TC2, Master 2 Research in Human-Computer Interaction). Download class part 1 Download class part 2 Download practical material Pure Data practical instruction (2012) Here is the binaural mixing program to complete. Try to finish it for this Thursday, before the next practical. Please feel free to contact me through email if you have any questions. I also included a WAV file of an audio example to be processed. It is a voice that I recorded some years ago. The recording is completely raw without any effect. You can use any kind of other sounds that you wish as long as it is a mono wave file without effects. Some information: Stages (1), (2) and (3) are finalized. You just need to add a stage (4), which will handle the filtering. You should first use a function to read the arraySrc, like tabplay~ . To apply the filter you have to use a convolution. You may apply it in the time or the frequency domain. The frequency domain is usually more efficient as it allows the use of the FFT (Fast Fourier Transform). Although FIR~ is chiefly designed to apply a Finite Impulse Response filter, it is also capable of applying a simple FFT convolution efficiently. An important point is that HRTF does not provide the intensity decrease with the distance following the Inverse Square Law . You should then use the dist_m variable from the stage (2) to apply this effect in the stage (4). To use a variable in Pd you can use the function r (which stands for \"receive\") followed by the variable name. The last stage should be a dac~ module to transmit the sound to your audio interface. Don't forget to tick the compute audio option in the main application window to hear some sound. These explanations are rather long, but the stage (4) is rather small and straightforward if you follow these steps. Extra: If you wish to observe the shape of the HRTF (HRIR actually) file, you can use Audacity to import it: File > Import > Raw Data... Use: 32 bit float; Little-endian; mono; 16 bytes offset; 44100 sample rate Good luck to you all!","title":"3D-Audio Class"},{"location":"3d-audio/#university-of-paris-sud-year-2-cs-master-tc-2","text":"Theoretical and practical material for the Fundamentals of Virtual and Augmented Reality class (TC2, Master 2 Research in Human-Computer Interaction). Download class part 1 Download class part 2 Download practical material","title":"University of Paris-Sud \u2014 Year 2 CS-Master (TC-2)"},{"location":"3d-audio/#pure-data-practical-instruction-2012","text":"Here is the binaural mixing program to complete. Try to finish it for this Thursday, before the next practical. Please feel free to contact me through email if you have any questions. I also included a WAV file of an audio example to be processed. It is a voice that I recorded some years ago. The recording is completely raw without any effect. You can use any kind of other sounds that you wish as long as it is a mono wave file without effects.","title":"Pure Data practical instruction (2012)"},{"location":"3d-audio/#some-information","text":"Stages (1), (2) and (3) are finalized. You just need to add a stage (4), which will handle the filtering. You should first use a function to read the arraySrc, like tabplay~ . To apply the filter you have to use a convolution. You may apply it in the time or the frequency domain. The frequency domain is usually more efficient as it allows the use of the FFT (Fast Fourier Transform). Although FIR~ is chiefly designed to apply a Finite Impulse Response filter, it is also capable of applying a simple FFT convolution efficiently. An important point is that HRTF does not provide the intensity decrease with the distance following the Inverse Square Law . You should then use the dist_m variable from the stage (2) to apply this effect in the stage (4). To use a variable in Pd you can use the function r (which stands for \"receive\") followed by the variable name. The last stage should be a dac~ module to transmit the sound to your audio interface. Don't forget to tick the compute audio option in the main application window to hear some sound. These explanations are rather long, but the stage (4) is rather small and straightforward if you follow these steps.","title":"Some information:"},{"location":"3d-audio/#extra","text":"If you wish to observe the shape of the HRTF (HRIR actually) file, you can use Audacity to import it: File > Import > Raw Data... Use: 32 bit float; Little-endian; mono; 16 bytes offset; 44100 sample rate Good luck to you all!","title":"Extra:"},{"location":"audio-dsp/","text":"University of Paris-Sud \u2014 Year 5 CS-Engineers (ET-5) Theoretical and practical material files for the 2014-2015 Polytech\u2019 Paris-Sud Et5 Audio signal processing class. They are under the Ipython Notebook 2 format. Download class 1 material Download class 2 material Download class 3 material Download class 4 material","title":"Audio-DSP Class"},{"location":"audio-dsp/#university-of-paris-sud-year-5-cs-engineers-et-5","text":"Theoretical and practical material files for the 2014-2015 Polytech\u2019 Paris-Sud Et5 Audio signal processing class. They are under the Ipython Notebook 2 format. Download class 1 material Download class 2 material Download class 3 material Download class 4 material","title":"University of Paris-Sud \u2014 Year 5 CS-Engineers (ET-5)"},{"location":"contact/","text":"mevrard@ina.fr","title":"Contact"},{"location":"contact/#amp109amp101amp118amp114amp97amp114amp100amp64amp105amp110amp97amp46amp102amp114","text":"","title":"\u0002amp\u0003#109;\u0002amp\u0003#101;\u0002amp\u0003#118;\u0002amp\u0003#114;\u0002amp\u0003#97;\u0002amp\u0003#114;\u0002amp\u0003#100;\u0002amp\u0003#64;\u0002amp\u0003#105;\u0002amp\u0003#110;\u0002amp\u0003#97;\u0002amp\u0003#46;\u0002amp\u0003#102;\u0002amp\u0003#114;"},{"location":"covid-19-resources/","text":"World Johns Hopkins Coronavirus Resource \u2013 COVID-19 Map Worldometer \u2013 Coronavirus Update Aatish Bhatia \u2013 Trajectory of World COVID-19 Confirmed Cases ECDC \u2013 COVID-19 situation update for the EU/EEA and the UK France French government \u2013 Covid-19 data and maps Le Monde \u2013 Hospitalized number per French department Belgium Sciensano \u2013 Epistat Covid-19 Japan Ministry of Health, Labour and Welfare \u2013 About Coronavirus Disease 2019 (COVID-19) Shane Reustle \u2013 Japan COVID-19 Coronavirus Tracker","title":"Covid-19 Resources"},{"location":"covid-19-resources/#world","text":"Johns Hopkins Coronavirus Resource \u2013 COVID-19 Map Worldometer \u2013 Coronavirus Update Aatish Bhatia \u2013 Trajectory of World COVID-19 Confirmed Cases ECDC \u2013 COVID-19 situation update for the EU/EEA and the UK","title":"World"},{"location":"covid-19-resources/#france","text":"French government \u2013 Covid-19 data and maps Le Monde \u2013 Hospitalized number per French department","title":"France"},{"location":"covid-19-resources/#belgium","text":"Sciensano \u2013 Epistat Covid-19","title":"Belgium"},{"location":"covid-19-resources/#japan","text":"Ministry of Health, Labour and Welfare \u2013 About Coronavirus Disease 2019 (COVID-19) Shane Reustle \u2013 Japan COVID-19 Coronavirus Tracker","title":"Japan"},{"location":"cpp/","text":"University of Paris-Sud \u2014 Year 4 CS-Engineers (ET-4) Practicals and project presentation PDF files for the 2014-2015 Polytech\u2019 Paris-Sud Et4 info class. Download practical 1 Download practical 2 Download practical 3 Download practical 4 Download project Eclipse-EGit Tutorial","title":"C++ Class"},{"location":"cpp/#university-of-paris-sud-year-4-cs-engineers-et-4","text":"Practicals and project presentation PDF files for the 2014-2015 Polytech\u2019 Paris-Sud Et4 info class. Download practical 1 Download practical 2 Download practical 3 Download practical 4 Download project Eclipse-EGit Tutorial","title":"University of Paris-Sud \u2014 Year 4 CS-Engineers (ET-4)"},{"location":"cv/","text":"Doctor of Science in Computer Science Status (since 2018): Research and development engineer at the National Audiovisual Institute (INA) , in France. Domains: Deep learning, Speech processing, NLP, digital humanities. Contact: mevrard@ina.fr Education 2012 -- 2015: Ph.D. in Computer Science at the LIMSI-CNRS -- University of Paris-Sud University of Paris-Sud (now Paris-Saclay ), in France. 2010: Preliminary complement to postgraduate education at the University of Li\u00e8ge (ULi\u00e8ge) , in Belgium. 2007: Audio engineering diploma at the SAE Institute Byron Bay , in Australia. 2002 -- 2004: Complementary Master in Business Administration at the Universit\u00e9 Libre de Bruxelles (ULB) , in Belgium. 1997 -- 2002: Master of Science in Industrial engineering at the Gramme Institute (now in HELMo) , in Belgium. Languages French: First language. English: Full professional proficiency. Dutch, Japanese: Basic. Other activities and Hobbies Music: Guitar, bass, and keyboard player in various rock and jazz bands since 1990. Audio engineering: Soundtrack production of 2 animated short-films (with Camera-etc , Li\u00e8ge, Belgium). Recording, mixing, and production of Rock, Jazz , and Electronic music . Other: Photography, cinema, reading, martial arts.","title":"Short CV"},{"location":"cv/#education","text":"2012 -- 2015: Ph.D. in Computer Science at the LIMSI-CNRS -- University of Paris-Sud University of Paris-Sud (now Paris-Saclay ), in France. 2010: Preliminary complement to postgraduate education at the University of Li\u00e8ge (ULi\u00e8ge) , in Belgium. 2007: Audio engineering diploma at the SAE Institute Byron Bay , in Australia. 2002 -- 2004: Complementary Master in Business Administration at the Universit\u00e9 Libre de Bruxelles (ULB) , in Belgium. 1997 -- 2002: Master of Science in Industrial engineering at the Gramme Institute (now in HELMo) , in Belgium.","title":"Education"},{"location":"cv/#languages","text":"French: First language. English: Full professional proficiency. Dutch, Japanese: Basic.","title":"Languages"},{"location":"cv/#other-activities-and-hobbies","text":"Music: Guitar, bass, and keyboard player in various rock and jazz bands since 1990. Audio engineering: Soundtrack production of 2 animated short-films (with Camera-etc , Li\u00e8ge, Belgium). Recording, mixing, and production of Rock, Jazz , and Electronic music . Other: Photography, cinema, reading, martial arts.","title":"Other activities and Hobbies"},{"location":"internships-m1/","text":"Internships \u2013 U-Paris-Saclay \u2013 2020-2021 During your 1 st year you have to do 2 groups of activities beyond classes (called \u201csoft skills\u201d): TER ( Travail d'Etude et de Recherche ) = Research training (Personal work supervised by a member of the master's teaching team) Internship OR \u201csummer\u201d school ( \u00e9cole th\u00e9matique ) OR participation in a challenge or Hackathon (5 ECTS) Although they are marked as belonging to different semesters, they can both be done whenever you like as long as they are completed at the end of June. Most students accomplish their TER during the 3 rd and 4 th trimester (January to April) and their internship in May and June. TER (research training) 1 day for 2 to 4 months Graded by the TER supervisor 5 ECTS During the 2 nd trimester (November to December) we will share research subjects proposed by the researchers of our labs, to be completed during the 3 rd or 4 th trimester. Some subjects can be taken by a group of students. This work can take the form of a review of the state of the art on a given scientific subject and/or the implementation of state of the art algorithms for the application on a given problem. You can also find a \u201cresearch training\u201d yourself. If it is outside of our labs, please check with us first. It is expected that you spend half a day to a day per week in the lab for 2 to 4 months (equivalent to a whole week of work full-time). The work is not remunerated. You hand in an (individual) report of your work of about 6 pages to the researchers that are supervising your work. They will give you a grade for your work. M1 Internship At least 1 month full time (or equivalent) No grade: PASS/NO PASS 5 ECTS If you choose to do an internship, you have to find a public research laboratory inside or outside of Paris-Saclay or a private company doing research in our field of AI and data science. We will also share with you some proposals. Your internship has to last at least 1 month, full-time work, or the equivalent in part-time work spread out over several months. If your internship lasts up to 2 months it may or may not be financially compensated, if it lasts longer, you must receive, by law, at least a small gratification, see service-public.fr (about 500\u20ac per month). You need to contact us before you start your internship so we approve of it and quite a few papers have to be signed. If you start before the signatures, you are not insured and the time already spent cannot be taken into account. You will not get a grade but you will need a proof signed by the person in the lab that is in charge of you, saying that you completed the internship successfully. You will have to hand us in an (individual) report of your work of about 4 pages. We can also validate an internship you completed during the summer 2020. Ecole th\u00e9matique (\u201csummer\u201d school) or hackathon (or challenge) At least 3 days full time of classes No grade: PASS/NO PASS 5 ECTS You can choose to replace the internship with a \u201csummer\u201d school (that can take place any time of the year, except in summer as it has to be completed before the end of June), or a Hackathon/challenge. You may contact us to validate a summer school you took in the summer 2020. We will make some proposals for schools, series or seminars, hackathons, or challenges you can participate in, some of which are competitive to enter. Check with us if you want to choose one that has not been proposed by us. At the end, we expect you to send a short report (2 pages maximum) with links to the classes you followed and the projects you finished to us. Instead of a summer school, it is also possible to select seminars \u00e0 la carte . You have to attend at least 6 seminars in our field (online or classroom) and write a paragraph for each seminar of what you learned in your own words, insisting on what it specifically brings to your fields of interest. For hackathons of challenges, you have to prove that you entered by showing your entries the challenge leaderboard and submit a short 2-page report, including the URL of the challenge and the URL of your Github repository.","title":"AI Informatics M1"},{"location":"internships-m1/#ter-research-training","text":"1 day for 2 to 4 months Graded by the TER supervisor 5 ECTS During the 2 nd trimester (November to December) we will share research subjects proposed by the researchers of our labs, to be completed during the 3 rd or 4 th trimester. Some subjects can be taken by a group of students. This work can take the form of a review of the state of the art on a given scientific subject and/or the implementation of state of the art algorithms for the application on a given problem. You can also find a \u201cresearch training\u201d yourself. If it is outside of our labs, please check with us first. It is expected that you spend half a day to a day per week in the lab for 2 to 4 months (equivalent to a whole week of work full-time). The work is not remunerated. You hand in an (individual) report of your work of about 6 pages to the researchers that are supervising your work. They will give you a grade for your work.","title":"TER (research training)"},{"location":"internships-m1/#m1-internship","text":"At least 1 month full time (or equivalent) No grade: PASS/NO PASS 5 ECTS If you choose to do an internship, you have to find a public research laboratory inside or outside of Paris-Saclay or a private company doing research in our field of AI and data science. We will also share with you some proposals. Your internship has to last at least 1 month, full-time work, or the equivalent in part-time work spread out over several months. If your internship lasts up to 2 months it may or may not be financially compensated, if it lasts longer, you must receive, by law, at least a small gratification, see service-public.fr (about 500\u20ac per month). You need to contact us before you start your internship so we approve of it and quite a few papers have to be signed. If you start before the signatures, you are not insured and the time already spent cannot be taken into account. You will not get a grade but you will need a proof signed by the person in the lab that is in charge of you, saying that you completed the internship successfully. You will have to hand us in an (individual) report of your work of about 4 pages. We can also validate an internship you completed during the summer 2020.","title":"M1 Internship"},{"location":"internships-m1/#ecole-thematique-summer-school-or-hackathon-or-challenge","text":"At least 3 days full time of classes No grade: PASS/NO PASS 5 ECTS You can choose to replace the internship with a \u201csummer\u201d school (that can take place any time of the year, except in summer as it has to be completed before the end of June), or a Hackathon/challenge. You may contact us to validate a summer school you took in the summer 2020. We will make some proposals for schools, series or seminars, hackathons, or challenges you can participate in, some of which are competitive to enter. Check with us if you want to choose one that has not been proposed by us. At the end, we expect you to send a short report (2 pages maximum) with links to the classes you followed and the projects you finished to us. Instead of a summer school, it is also possible to select seminars \u00e0 la carte . You have to attend at least 6 seminars in our field (online or classroom) and write a paragraph for each seminar of what you learned in your own words, insisting on what it specifically brings to your fields of interest. For hackathons of challenges, you have to prove that you entered by showing your entries the challenge leaderboard and submit a short 2-page report, including the URL of the challenge and the URL of your Github repository.","title":"Ecole th\u00e9matique (\u201csummer\u201d school) or hackathon (or challenge)"},{"location":"internships-m2/","text":"Internships \u2013 U-Paris-Saclay \u2013 2020-2021 M2 internship introduction For your internship, you have to find a public research laboratory inside or outside of Paris-Saclay or a private company doing research in our field of AI and data science. We will also share with you some proposals. Your internship has to last at least 5 months of full-time work. It must be financially remunerated, by law, see service-public.fr . It takes place between February and August of your 2 nd master year and must end before August 31, 2021. Your internship must go through an approval process. You need to contact us and quite a few papers have to be signed. Do not start before you get all signatures: you would not be insured and the time already spent cannot be taken into account . At the end of the internship, you will be asked to make an oral presentation and a report of a quality approaching that of a communication to a workshop or a conference. The internship will be graded and is worth 30 ECTS. Recommendations The internships can include data analyses, method comparisons, and/or theoretical analyses (we discourage software development only internships). You should have received already a link to the list of proposed internships Internship offer [AI] informatics master (Responses) which will keep growing. We encourage you to also search on your own. Companies such as Microsoft, Google, Facebook, Thales, Safran, RTE, Datadog, Dassault, Schlumberger, BNP Paribas, Soci\u00e9t\u00e9 G\u00e9n\u00e9rale, Total, IFP, Renault, Guerlain, 4Paradigm, Airbus, Quantcube, Essilor, Unilever, NukkAI, Onera, GE healthcare, Thomson, and research labs at Paris-Saclay (INRIA, CNRS, CEA) have been offering internships in the past to our students. Subscribe to various mailing lists, such as Bulle-i3 (general CS), ATALA (NLP), or Parole (Speech), where you'll find internship adds. Also, get in touch with teachers or researchers whose fields you're interested in. Application Please start applying now, and fill-up the form: Internship \u2013 Master AI Paris-Saclay 2020-2021 before November 15, 2020 , with 2 to 4 internships you have selected, in the proposed list Internship offer [AI] informatics master (Responses) or among other sources. But do not wait until then to start applying! If you find an internship not listed yet, please fill the form: Internship offer [AI] informatics master with the required information, and add your name in the field: \u201cName of a student from our program that you want to direct this internship to\u201d.","title":"AI Informatics M2"},{"location":"internships-m2/#m2-internship-introduction","text":"For your internship, you have to find a public research laboratory inside or outside of Paris-Saclay or a private company doing research in our field of AI and data science. We will also share with you some proposals. Your internship has to last at least 5 months of full-time work. It must be financially remunerated, by law, see service-public.fr . It takes place between February and August of your 2 nd master year and must end before August 31, 2021. Your internship must go through an approval process. You need to contact us and quite a few papers have to be signed. Do not start before you get all signatures: you would not be insured and the time already spent cannot be taken into account . At the end of the internship, you will be asked to make an oral presentation and a report of a quality approaching that of a communication to a workshop or a conference. The internship will be graded and is worth 30 ECTS.","title":"M2 internship introduction"},{"location":"internships-m2/#recommendations","text":"The internships can include data analyses, method comparisons, and/or theoretical analyses (we discourage software development only internships). You should have received already a link to the list of proposed internships Internship offer [AI] informatics master (Responses) which will keep growing. We encourage you to also search on your own. Companies such as Microsoft, Google, Facebook, Thales, Safran, RTE, Datadog, Dassault, Schlumberger, BNP Paribas, Soci\u00e9t\u00e9 G\u00e9n\u00e9rale, Total, IFP, Renault, Guerlain, 4Paradigm, Airbus, Quantcube, Essilor, Unilever, NukkAI, Onera, GE healthcare, Thomson, and research labs at Paris-Saclay (INRIA, CNRS, CEA) have been offering internships in the past to our students. Subscribe to various mailing lists, such as Bulle-i3 (general CS), ATALA (NLP), or Parole (Speech), where you'll find internship adds. Also, get in touch with teachers or researchers whose fields you're interested in.","title":"Recommendations"},{"location":"internships-m2/#application","text":"Please start applying now, and fill-up the form: Internship \u2013 Master AI Paris-Saclay 2020-2021 before November 15, 2020 , with 2 to 4 internships you have selected, in the proposed list Internship offer [AI] informatics master (Responses) or among other sources. But do not wait until then to start applying! If you find an internship not listed yet, please fill the form: Internship offer [AI] informatics master with the required information, and add your name in the field: \u201cName of a student from our program that you want to direct this internship to\u201d.","title":"Application"},{"location":"publi/","text":"M. Evrard, R. Uro, N. Herv\u00e9, and B. Mazoyer, \u201cFrench Tweet Corpus for Automatic StanceDetection,\u201d International Conference on Language Resources and Evaluation (LREC), 2020. R. Uro, M. Evrard, N. Herv\u00e9, and B. Mazoyer, \u201cThe Constitution of a French Tweet Corpus for Automatic Stance Detection,\u201d SLSP 2019, Ljubljana, Slovenia, 2019. D. Doukhan, E. Lechapt, M. Evrard, and J. Carrive, \u201cINA\u2019S MIREX 2018 music and speech detection system,\u201d in Music Information Retrieval Evaluation eXchange (MIREX), 2018. A. Rilliard, C. d\u2019Alessandro, and M. Evrard, \u201cParadigmatic variation of vowels in expressive speech: acoustic description and dimensional analysis,\u201d in Journal of the Acoustical Society of Americal (Jasa), 2018. M. Evrard, M. Miwa. and Y. Sasaki, \u201cSemantic graph embeddings and a neural language model for WSD,\u201d Second International Workshop on Symbolic-Neural Learning (SNL), 2018. M. Evrard, M. Miwa. and Y. Sasaki, \u201cTTI's Approaches to Symbolic-Neural Learning,\u201d First International Workshop on Symbolic-Neural Learning (SNL), 2017. M. Evrard, \u201cSynth\u00e8se de parole expressive \u00e0 partir du texte: Des phonostyles au contr\u00f4le gestuel pour la synth\u00e8se param\u00e9trique statistique,\u201d PhD thesis, Universit\u00e9 de Paris-Sud, 2015. M. Evrard, S. Delalez, C. d\u2019Alessandro, and A. Rilliard, \u201cComparison of chironomic stylization versus statistical modeling of prosody for expressive speech synthesis,\u201d in Sixteenth Annual Conference of the International Speech Communication Association (INTERSPEECH), 2015. M. Evrard, C. d\u2019Alessandro, and A. Rilliard, \u201cEvaluation of the impact of corpus phonetic alignment on the hmm-based speech synthesis quality,\u201d in Statistical Language and Speech Processing, Springer, 2015. C.-T. Do, M. Evrard, A. Leman, C. d\u2019Alessandro, A. Rilliard, and J.-L. Crebouw, \u201cObjective evaluation of hmm-based speech synthesis system using Kullback-Leibler divergence,\u201d in Fifteenth Annual Conference of the International Speech Communication Association (INTERSPEECH), 2014. M. Evrard, C. R. Andr\u00e9, J. G. Verly, J.-J. Embrechts, and B. F. Katz, \u201cObject-based sound re-mix for the spatially coherent audio rendering of an existing stereoscopic-3D animation movie,\u201d in Audio Engineering Society Convention 131, Audio Engineering Society, New York, NY, United States, 2011. M. Evrard, C. Andr\u00e9, J. Verly, and J.-J. Embrechts, \u201cAdding wave-field-synthesis 3D audio to an existing stereoscopic-3D animation movie,\u201d in Third edition of the 3D Stereo MEDIA international summit, Li\u00e8ge, Belgium, 2011. M. Evrard, C. Andr\u00e9, J.-J. Embrechts, and J. Verly, \u201c3D audio acquisition and reproduction systems,\u201d in Journ\u00e9e ABAV (Association Belge des Acousticiens), Neder-over-Heembeek, Belgium, 2011. M. Evrard, A. Rilliard, and C. d\u2019Alessandro, \u201cReproduction de la personnalit\u00e9 vocale d\u2019un acteur,\u201d in Journ\u00e9es Jeunes Chercheurs en Audition, Acoustique musicale, et Signal audio (JJCAAS), Marseille, France, 2012. M. Evrard, A. Rilliard, and C. d\u2019Alessandro, \u201cCaract\u00e9risation et reproduction de la personnalit\u00e9 vocale d\u2019un acteur,\u201d in Journ\u00e9e des Doctorants du LIMSI-CNRS (JDD), Orsay, France, 2012.","title":"Publications"},{"location":"thesis/","text":"Expressive Text-to-Speech Synthesis From Phonostyles to Gestural Control for Parametric Statistic Synthesis (Written in French, title and abstract are here translated in English) The subject of this thesis was the study and conception of a platform for expressive speech synthesis. The LIPS\u00b3 Text-to-Speech system \u2014 developed in the context of this thesis \u2014 includes a linguistic module and a parametric statistical module (built upon HTS and STRAIGHT). The system was based on a new single-speaker corpus, designed, recorded and annotated. The first study analyzed the influence of the precision of the training corpus phonetic labeling on the synthesis quality. It showed that statistical parametric synthesis is robust to labeling and alignment errors. This addresses the issue of variation in phonetic realizations for expressive speech. The second study presents an acoustic-phonetic analysis of the corpus, characterizing the expressive space used by the speaker to instantiate the instructions that described the different expressive conditions. Voice source parameters and articulatory settings were analyzed according to their phonetic classes, which allowed for a fine phonostylistic characterization. The third study focused on intonation and rhythm. Calliphony 2.0 is a real-time chironomic interface that controls the f0 and rhythmic parameters of prosody, using drawing/writing hand gestures with a stylus and a graphics tablet. These hand-controlled modulations are used to enhance the TTS output, producing speech that is more realistic, without degradation as it is directly applied to the vocoder parameters. Intonation and rhythm stylization using this interface brings significant improvement to the prototypicality of expressivity, as well as to the general quality of synthetic speech. These studies show that parametric statistical synthesis, combined with a chironomic interface, offers an efficient solution for expressive speech synthesis, as well as a powerful tool for the study of prosody. Keywords: Expressive speech synthesis, gestural control, prosody, parametric statistical speech synthesis, adaptative training, HTS.","title":"Thesis"},{"location":"thesis/#expressive-text-to-speech-synthesis","text":"","title":"Expressive Text-to-Speech Synthesis"},{"location":"thesis/#from-phonostyles-to-gestural-control-for-parametric-statistic-synthesis","text":"(Written in French, title and abstract are here translated in English) The subject of this thesis was the study and conception of a platform for expressive speech synthesis. The LIPS\u00b3 Text-to-Speech system \u2014 developed in the context of this thesis \u2014 includes a linguistic module and a parametric statistical module (built upon HTS and STRAIGHT). The system was based on a new single-speaker corpus, designed, recorded and annotated. The first study analyzed the influence of the precision of the training corpus phonetic labeling on the synthesis quality. It showed that statistical parametric synthesis is robust to labeling and alignment errors. This addresses the issue of variation in phonetic realizations for expressive speech. The second study presents an acoustic-phonetic analysis of the corpus, characterizing the expressive space used by the speaker to instantiate the instructions that described the different expressive conditions. Voice source parameters and articulatory settings were analyzed according to their phonetic classes, which allowed for a fine phonostylistic characterization. The third study focused on intonation and rhythm. Calliphony 2.0 is a real-time chironomic interface that controls the f0 and rhythmic parameters of prosody, using drawing/writing hand gestures with a stylus and a graphics tablet. These hand-controlled modulations are used to enhance the TTS output, producing speech that is more realistic, without degradation as it is directly applied to the vocoder parameters. Intonation and rhythm stylization using this interface brings significant improvement to the prototypicality of expressivity, as well as to the general quality of synthetic speech. These studies show that parametric statistical synthesis, combined with a chironomic interface, offers an efficient solution for expressive speech synthesis, as well as a powerful tool for the study of prosody. Keywords: Expressive speech synthesis, gestural control, prosody, parametric statistical speech synthesis, adaptative training, HTS.","title":"From Phonostyles to Gestural Control for Parametric Statistic Synthesis"}]}